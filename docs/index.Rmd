---
title: 'Unsupervised Learning : Discovering Latent Variables in High-Dimensional Data using Exploratory Factor Analysis'
author: "John Pauline Pineda"
date: "August 10, 2023"
output: 
  html_document:
    toc: true
    toc_depth: 3
    theme: readable
    highlight: tango
    css: doc.css
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, fig.width=15, fig.height=10)
```

# **1. Table of Contents**
|
|
##  1.1 Sample Data
|
| The [<mark style="background-color: #EEEEEE;color: #FF0000">**JobHiring**</mark>](https://real-statistics.com/multivariate-statistics/factor-analysis/factor-analysis-example/) dataset obtained from the [<mark style="background-color: #CCECFF">**Statistics By Jim**</mark>](https://statisticsbyjim.com/basics/factor-analysis/) website by [Jim Frost](https://statisticsbyjim.com/jim_frost/) was used for this illustrated example.   
|
| Preliminary dataset assessment:
|
| **[A]** 50 rows (observations)
| 
| **[B]** 12 columns (variables)
|      **[B.1]** 12/12 descriptors = 12/12 ordered category 
|             **[B.1.1]** <span style="color: #FF0000">ACAD</span> (Academic Record)
|             **[B.1.2]** <span style="color: #FF0000">APPR</span> (Appearance)
|             **[B.1.3]** <span style="color: #FF0000">COMM</span> (Communication)
|             **[B.1.4]** <span style="color: #FF0000">CFIT</span> (Company Fit)
|             **[B.1.5]** <span style="color: #FF0000">EXPR</span> (Experience)
|             **[B.1.6]** <span style="color: #FF0000">JFIT</span> (Job Fit)
|             **[B.1.7]** <span style="color: #FF0000">LETT</span> (Cover Letter)
|             **[B.1.8]** <span style="color: #FF0000">LIKE</span> (Likeability)
|             **[B.1.9]** <span style="color: #FF0000">ORGN</span> (Organization)
|             **[B.1.10]** <span style="color: #FF0000">POTL</span> (Potential)
|             **[B.1.11]** <span style="color: #FF0000">RESM</span> (Resume)
|             **[B.1.12]** <span style="color: #FF0000">SCON</span> (Self-Confidence)
|     
| 

<details><summary><mark style="background-color: #000000;color: #FFFFFF">**Code Chunk | Output**</mark></summary>

```{r section_1.1, warning=FALSE, message=FALSE}
##################################
# Loading R libraries
##################################
library(AppliedPredictiveModeling)
library(performance)
library(parameters)
library(caret)
library(psych)
library(lattice)
library(dplyr)
library(moments)
library(skimr)
library(RANN)
library(pls)
library(corrplot)
library(lares)
library(DMwR)
library(gridExtra)
library(rattle)
library(RColorBrewer)
library(stats)
library(factoextra)
library(FactoMineR)
library(gplots)
library(qgraph)
library(ggplot2)
library(psych)
library(nFactors)
library(MBESS)
library(DandEFA)
library(EFAtools)


##################################
# Loading source and
# formulating the analysis set
##################################
JobHiring <- read.csv("JobHiring.csv",
                   na.strings=c("NA","NaN"," ",""),
                   stringsAsFactors = FALSE)
JobHiring <- as.data.frame(JobHiring)

##################################
# Performing a general exploration of the data set
##################################
dim(JobHiring)
str(JobHiring)
summary(JobHiring)

##################################
# Formulating a data type assessment summary
##################################
PDA <- JobHiring
(PDA.Summary <- data.frame(
  Column.Index=c(1:length(names(PDA))),
  Column.Name= names(PDA), 
  Column.Type=sapply(PDA, function(x) class(x)), 
  row.names=NULL)
)

```

</details>

##  1.2 Data Quality Assessment
|
| Data quality assessment:
|
| **[A]** No missing observations noted for any variable.
|
| **[B]** No low variance observed for any variable with First.Second.Mode.Ratio>5.
|
| **[C]** No low variance observed for any variable with Unique.Count.Ratio<0.01.
|
| **[D]** No high skewness observed for any variable with Skewness>3 or Skewness<(-3).
|
|

<details><summary><mark style="background-color: #000000;color: #FFFFFF">**Code Chunk | Output**</mark></summary>

```{r section_1.2, warning=FALSE, message=FALSE}
##################################
# Loading dataset
##################################
DQA <- JobHiring

##################################
# Formulating an overall data quality assessment summary
##################################
(DQA.Summary <- data.frame(
  Column.Name= names(DQA),
  Column.Type=sapply(DQA, function(x) class(x)),
  Row.Count=sapply(DQA, function(x) nrow(DQA)),
  NA.Count=sapply(DQA,function(x)sum(is.na(x))),
  Fill.Rate=sapply(DQA,function(x)format(round((sum(!is.na(x))/nrow(DQA)),3),nsmall=3)),
  row.names=NULL)
)

##################################
# Listing all descriptors
##################################
DQA.Descriptors <- DQA

##################################
# Listing all numeric Descriptors
##################################
DQA.Descriptors.Numeric <- DQA.Descriptors[,sapply(DQA.Descriptors, is.numeric)]

if (length(names(DQA.Descriptors.Numeric))>0) {
    print(paste0("There are ",
               (length(names(DQA.Descriptors.Numeric))),
               " numeric descriptor variable(s)."))
} else {
  print("There are no numeric descriptor variables.")
}

##################################
# Listing all factor Descriptors
##################################
DQA.Descriptors.Factor <- DQA.Descriptors[,sapply(DQA.Descriptors, is.factor)]

if (length(names(DQA.Descriptors.Factor))>0) {
    print(paste0("There are ",
               (length(names(DQA.Descriptors.Factor))),
               " factor descriptor variable(s)."))
} else {
  print("There are no factor descriptor variables.")
}

##################################
# Formulating a data quality assessment summary for factor Descriptors
##################################
if (length(names(DQA.Descriptors.Factor))>0) {

  ##################################
  # Formulating a function to determine the first mode
  ##################################
  FirstModes <- function(x) {
    ux <- unique(na.omit(x))
    tab <- tabulate(match(x, ux))
    ux[tab == max(tab)]
  }

  ##################################
  # Formulating a function to determine the second mode
  ##################################
  SecondModes <- function(x) {
    ux <- unique(na.omit(x))
    tab <- tabulate(match(x, ux))
    fm = ux[tab == max(tab)]
    sm = x[!(x %in% fm)]
    usm <- unique(sm)
    tabsm <- tabulate(match(sm, usm))
    ifelse(is.na(usm[tabsm == max(tabsm)])==TRUE,
           return("x"),
           return(usm[tabsm == max(tabsm)]))
  }

  (DQA.Descriptors.Factor.Summary <- data.frame(
  Column.Name= names(DQA.Descriptors.Factor),
  Column.Type=sapply(DQA.Descriptors.Factor, function(x) class(x)),
  Unique.Count=sapply(DQA.Descriptors.Factor, function(x) length(unique(x))),
  First.Mode.Value=sapply(DQA.Descriptors.Factor, function(x) as.character(FirstModes(x)[1])),
  Second.Mode.Value=sapply(DQA.Descriptors.Factor, function(x) as.character(SecondModes(x)[1])),
  First.Mode.Count=sapply(DQA.Descriptors.Factor, function(x) sum(na.omit(x) == FirstModes(x)[1])),
  Second.Mode.Count=sapply(DQA.Descriptors.Factor, function(x) sum(na.omit(x) == SecondModes(x)[1])),
  Unique.Count.Ratio=sapply(DQA.Descriptors.Factor, function(x) format(round((length(unique(x))/nrow(DQA.Descriptors.Factor)),3), nsmall=3)),
  First.Second.Mode.Ratio=sapply(DQA.Descriptors.Factor, function(x) format(round((sum(na.omit(x) == FirstModes(x)[1])/sum(na.omit(x) == SecondModes(x)[1])),3), nsmall=3)),
  row.names=NULL)
  )

}

##################################
# Formulating a data quality assessment summary for numeric Descriptors
##################################
if (length(names(DQA.Descriptors.Numeric))>0) {

  ##################################
  # Formulating a function to determine the first mode
  ##################################
  FirstModes <- function(x) {
    ux <- unique(na.omit(x))
    tab <- tabulate(match(x, ux))
    ux[tab == max(tab)]
  }

  ##################################
  # Formulating a function to determine the second mode
  ##################################
  SecondModes <- function(x) {
    ux <- unique(na.omit(x))
    tab <- tabulate(match(x, ux))
    fm = ux[tab == max(tab)]
    sm = na.omit(x)[!(na.omit(x) %in% fm)]
    usm <- unique(sm)
    tabsm <- tabulate(match(sm, usm))
    ifelse(is.na(usm[tabsm == max(tabsm)])==TRUE,
           return(0.00001),
           return(usm[tabsm == max(tabsm)]))
  }

  (DQA.Descriptors.Numeric.Summary <- data.frame(
  Column.Name= names(DQA.Descriptors.Numeric),
  Column.Type=sapply(DQA.Descriptors.Numeric, function(x) class(x)),
  Unique.Count=sapply(DQA.Descriptors.Numeric, function(x) length(unique(x))),
  Unique.Count.Ratio=sapply(DQA.Descriptors.Numeric, function(x) format(round((length(unique(x))/nrow(DQA.Descriptors.Numeric)),3), nsmall=3)),
  First.Mode.Value=sapply(DQA.Descriptors.Numeric, function(x) format(round((FirstModes(x)[1]),3),nsmall=3)),
  Second.Mode.Value=sapply(DQA.Descriptors.Numeric, function(x) format(round((SecondModes(x)[1]),3),nsmall=3)),
  First.Mode.Count=sapply(DQA.Descriptors.Numeric, function(x) sum(na.omit(x) == FirstModes(x)[1])),
  Second.Mode.Count=sapply(DQA.Descriptors.Numeric, function(x) sum(na.omit(x) == SecondModes(x)[1])),
  First.Second.Mode.Ratio=sapply(DQA.Descriptors.Numeric, function(x) format(round((sum(na.omit(x) == FirstModes(x)[1])/sum(na.omit(x) == SecondModes(x)[1])),3), nsmall=3)),
  Minimum=sapply(DQA.Descriptors.Numeric, function(x) format(round(min(x,na.rm = TRUE),3), nsmall=3)),
  Mean=sapply(DQA.Descriptors.Numeric, function(x) format(round(mean(x,na.rm = TRUE),3), nsmall=3)),
  Median=sapply(DQA.Descriptors.Numeric, function(x) format(round(median(x,na.rm = TRUE),3), nsmall=3)),
  Maximum=sapply(DQA.Descriptors.Numeric, function(x) format(round(max(x,na.rm = TRUE),3), nsmall=3)),
  Skewness=sapply(DQA.Descriptors.Numeric, function(x) format(round(skewness(x,na.rm = TRUE),3), nsmall=3)),
  Kurtosis=sapply(DQA.Descriptors.Numeric, function(x) format(round(kurtosis(x,na.rm = TRUE),3), nsmall=3)),
  Percentile25th=sapply(DQA.Descriptors.Numeric, function(x) format(round(quantile(x,probs=0.25,na.rm = TRUE),3), nsmall=3)),
  Percentile75th=sapply(DQA.Descriptors.Numeric, function(x) format(round(quantile(x,probs=0.75,na.rm = TRUE),3), nsmall=3)),
  row.names=NULL)
  )

}

##################################
# Identifying potential data quality issues
##################################

##################################
# Checking for missing observations
##################################
if ((nrow(DQA.Summary[DQA.Summary$NA.Count>0,]))>0){
  print(paste0("Missing observations noted for ",
               (nrow(DQA.Summary[DQA.Summary$NA.Count>0,])),
               " variable(s) with NA.Count>0 and Fill.Rate<1.0."))
  DQA.Summary[DQA.Summary$NA.Count>0,]
} else {
  print("No missing observations noted.")
}

##################################
# Checking for zero or near-zero variance Descriptors
##################################
if (length(names(DQA.Descriptors.Factor))==0) {
  print("No factor descriptors noted.")
} else if (nrow(DQA.Descriptors.Factor.Summary[as.numeric(as.character(DQA.Descriptors.Factor.Summary$First.Second.Mode.Ratio))>5,])>0){
  print(paste0("Low variance observed for ",
               (nrow(DQA.Descriptors.Factor.Summary[as.numeric(as.character(DQA.Descriptors.Factor.Summary$First.Second.Mode.Ratio))>5,])),
               " factor variable(s) with First.Second.Mode.Ratio>5."))
  DQA.Descriptors.Factor.Summary[as.numeric(as.character(DQA.Descriptors.Factor.Summary$First.Second.Mode.Ratio))>5,]
} else {
  print("No low variance factor descriptors due to high first-second mode ratio noted.")
}

if (length(names(DQA.Descriptors.Numeric))==0) {
  print("No numeric descriptors noted.")
} else if (nrow(DQA.Descriptors.Numeric.Summary[as.numeric(as.character(DQA.Descriptors.Numeric.Summary$First.Second.Mode.Ratio))>5,])>0){
  print(paste0("Low variance observed for ",
               (nrow(DQA.Descriptors.Numeric.Summary[as.numeric(as.character(DQA.Descriptors.Numeric.Summary$First.Second.Mode.Ratio))>5,])),
               " numeric variable(s) with First.Second.Mode.Ratio>5."))
  DQA.Descriptors.Numeric.Summary[as.numeric(as.character(DQA.Descriptors.Numeric.Summary$First.Second.Mode.Ratio))>5,]
} else {
  print("No low variance numeric descriptors due to high first-second mode ratio noted.")
}

if (length(names(DQA.Descriptors.Numeric))==0) {
  print("No numeric descriptors noted.")
} else if (nrow(DQA.Descriptors.Numeric.Summary[as.numeric(as.character(DQA.Descriptors.Numeric.Summary$Unique.Count.Ratio))<0.01,])>0){
  print(paste0("Low variance observed for ",
               (nrow(DQA.Descriptors.Numeric.Summary[as.numeric(as.character(DQA.Descriptors.Numeric.Summary$Unique.Count.Ratio))<0.01,])),
               " numeric variable(s) with Unique.Count.Ratio<0.01."))
  DQA.Descriptors.Numeric.Summary[as.numeric(as.character(DQA.Descriptors.Numeric.Summary$Unique.Count.Ratio))<0.01,]
} else {
  print("No low variance numeric descriptors due to low unique count ratio noted.")
}

##################################
# Checking for skewed Descriptors
##################################
if (length(names(DQA.Descriptors.Numeric))==0) {
  print("No numeric descriptors noted.")
} else if (nrow(DQA.Descriptors.Numeric.Summary[as.numeric(as.character(DQA.Descriptors.Numeric.Summary$Skewness))>3 |
                                               as.numeric(as.character(DQA.Descriptors.Numeric.Summary$Skewness))<(-3),])>0){
  print(paste0("High skewness observed for ",
  (nrow(DQA.Descriptors.Numeric.Summary[as.numeric(as.character(DQA.Descriptors.Numeric.Summary$Skewness))>3 |
                                               as.numeric(as.character(DQA.Descriptors.Numeric.Summary$Skewness))<(-3),])),
  " numeric variable(s) with Skewness>3 or Skewness<(-3)."))
  DQA.Descriptors.Numeric.Summary[as.numeric(as.character(DQA.Descriptors.Numeric.Summary$Skewness))>3 |
                                 as.numeric(as.character(DQA.Descriptors.Numeric.Summary$Skewness))<(-3),]
} else {
  print("No skewed numeric descriptors noted.")
}
```

</details>

##  1.3 Data Preprocessing

###  1.3.1 Outlier Detection
|
| **[A]** Outliers noted for 3 out of the 12 descriptors. Descriptor values were visualized through a boxplot including observations classified as suspected outliers using the IQR criterion. The IQR criterion means that all observations above the (75th percentile + 1.5 x IQR) or below the (25th percentile - 1.5 x IQR) are suspected outliers, where IQR is the difference between the third quartile (75th percentile) and first quartile (25th percentile).
|      **[A.1]** <span style="color: #FF0000">APPR</span> = 2
|      **[A.2]** <span style="color: #FF0000">LIKE</span> = 3
|      **[A.3]** <span style="color: #FF0000">SCON</span> = 4
|
|

<details><summary><mark style="background-color: #000000;color: #FFFFFF">**Code Chunk | Output**</mark></summary>

```{r section_1.3.1.1, warning=FALSE, message=FALSE}
##################################
# Loading dataset
##################################
DPA <- JobHiring

##################################
# Gathering descriptive statistics
##################################
(DPA_Skimmed <- skim(DPA))

```

```{r section_1.3.1.2, warning=FALSE, message=FALSE, fig.width=15, fig.height=2}
##################################
# Outlier Detection
##################################

##################################
# Listing all Descriptors
##################################
DPA.Descriptors <- DPA

##################################
# Listing all numeric Descriptors
##################################
DPA.Descriptors.Numeric <- DPA.Descriptors[,sapply(DPA.Descriptors, is.numeric)]

##################################
# Identifying outliers for the numeric Descriptors
##################################
OutlierCountList <- c()

for (i in 1:ncol(DPA.Descriptors.Numeric)) {
  Outliers <- boxplot.stats(DPA.Descriptors.Numeric[,i])$out
  OutlierCount <- length(Outliers)
  OutlierCountList <- append(OutlierCountList,OutlierCount)
  OutlierIndices <- which(DPA.Descriptors.Numeric[,i] %in% c(Outliers))
  print(
  ggplot(DPA.Descriptors.Numeric, aes(x=DPA.Descriptors.Numeric[,i])) +
  geom_boxplot() +
  theme_bw() +
  theme(axis.text.y=element_blank(), 
        axis.ticks.y=element_blank()) +
  xlab(names(DPA.Descriptors.Numeric)[i]) +
  labs(title=names(DPA.Descriptors.Numeric)[i],
       subtitle=paste0(OutlierCount, " Outlier(s) Detected")))
}


```

</details>

###  1.3.2 Zero and Near-Zero Variance
|
| **[A]** No low variance observed for any descriptor using a preprocessing summary from the <mark style="background-color: #CCECFF">**caret**</mark> package. The <span style="color: #0000FF">nearZeroVar</span> method using both the <span style="color: #0000FF">freqCut</span> and <span style="color: #0000FF">uniqueCut</span> criteria set at 95/5 and 10, respectively, were applied on the dataset.
|
|

<details><summary><mark style="background-color: #000000;color: #FFFFFF">**Code Chunk | Output**</mark></summary>

```{r section_1.3.2, warning=FALSE, message=FALSE}
##################################
# Zero and Near-Zero Variance
##################################

##################################
# Identifying columns with low variance
###################################
DPA_LowVariance <- nearZeroVar(DPA,
                               freqCut = 80/20,
                               uniqueCut = 10,
                               saveMetrics= TRUE)
(DPA_LowVariance[DPA_LowVariance$nzv,])

if ((nrow(DPA_LowVariance[DPA_LowVariance$nzv,]))==0){
  
  print("No low variance descriptors noted.")
  
} else {

  print(paste0("Low variance observed for ",
               (nrow(DPA_LowVariance[DPA_LowVariance$nzv,])),
               " numeric variable(s) with First.Second.Mode.Ratio>4 and Unique.Count.Ratio<0.10."))
  
  DPA_LowVarianceForRemoval <- (nrow(DPA_LowVariance[DPA_LowVariance$nzv,]))
  
  print(paste0("Low variance can be resolved by removing ",
               (nrow(DPA_LowVariance[DPA_LowVariance$nzv,])),
               " numeric variable(s)."))
  
  for (j in 1:DPA_LowVarianceForRemoval) {
  DPA_LowVarianceRemovedVariable <- rownames(DPA_LowVariance[DPA_LowVariance$nzv,])[j]
  print(paste0("Variable ",
               j,
               " for removal: ",
               DPA_LowVarianceRemovedVariable))
  }
  
  DPA %>%
  skim() %>%
  dplyr::filter(skim_variable %in% rownames(DPA_LowVariance[DPA_LowVariance$nzv,]))

}

```

</details>

###  1.3.3 Collinearity
|
| **[A]** No multicollinearity with Pearson correlation coefficients >80% was noted among pairs of descriptors using the preprocessing summary from the <mark style="background-color: #CCECFF">**caret**</mark> package.
|
|

<details><summary><mark style="background-color: #000000;color: #FFFFFF">**Code Chunk | Output**</mark></summary>

```{r section_1.3.3, warning=FALSE, message=FALSE}
##################################
# Visualizing pairwise correlation between descriptor
##################################
(DPA_Correlation <- cor(DPA.Descriptors.Numeric,
                        method = "pearson",
                        use="pairwise.complete.obs"))

DPA_CorrelationTest <- cor.mtest(DPA.Descriptors.Numeric,
                       method = "pearson",
                       conf.level = 0.95)

corrplot(cor(DPA.Descriptors.Numeric,
             method = "pearson",
             use="pairwise.complete.obs"),
             method = "circle",
             type = "upper",
             order = "original",
             tl.col = "black",
             tl.cex = 0.75,
             tl.srt = 90,
             sig.level = 0.05,
             p.mat = DPA_CorrelationTest$p,
             insig = "blank")

corrplot(cor(DPA.Descriptors.Numeric,
             method = "pearson",
             use="pairwise.complete.obs"),
             method = "number",
             type = "upper",
             order = "original",
             tl.col = "black",
             tl.cex = 0.75,
             tl.srt = 90,
             sig.level = 0.05,
             p.mat = DPA_CorrelationTest$p,
             insig = "blank")

##################################
# Identifying the highly correlated variables
##################################
(DPA_HighlyCorrelatedCount <- sum(abs(DPA_Correlation[upper.tri(DPA_Correlation)])>0.90))

if (DPA_HighlyCorrelatedCount > 0) {
  DPA_HighlyCorrelated <- findCorrelation(DPA_Correlation, cutoff = 0.90)

  (DPA_HighlyCorrelatedForRemoval <- length(DPA_HighlyCorrelated))

  print(paste0("High correlation can be resolved by removing ",
               (DPA_HighlyCorrelatedForRemoval),
               " numeric variable(s)."))

  for (j in 1:DPA_HighlyCorrelatedForRemoval) {
  DPA_HighlyCorrelatedRemovedVariable <- colnames(DPA.Predictors.Numeric)[DPA_HighlyCorrelated[j]]
  print(paste0("Variable ",
               j,
               " for removal: ",
               DPA_HighlyCorrelatedRemovedVariable))
  }

}



```

</details>

###  1.3.4 Linear Dependency
|
| **[A]** No linear dependencies noted for any subset of decriptors using the preprocessing summary from the <mark style="background-color: #CCECFF">**caret**</mark> package applying the <span style="color: #0000FF">findLinearCombos</span> method which utilizes the QR decomposition of a matrix to enumerate sets of linear combinations (if they exist). 
|
|

<details><summary><mark style="background-color: #000000;color: #FFFFFF">**Code Chunk | Output**</mark></summary>

```{r section_1.3.4, warning=FALSE, message=FALSE}
##################################
# Linear Dependencies
##################################

##################################
# Finding linear dependencies
##################################
DPA_LinearlyDependent <- findLinearCombos(DPA.Descriptors.Numeric)

##################################
# Identifying the linearly dependent variables
##################################
DPA_LinearlyDependent <- findLinearCombos(DPA.Descriptors.Numeric)

(DPA_LinearlyDependentCount <- length(DPA_LinearlyDependent$linearCombos))

if (DPA_LinearlyDependentCount == 0) {
  print("No linearly dependent predictors noted.")
} else {
  print(paste0("Linear dependency observed for ",
               (DPA_LinearlyDependentCount),
               " subset(s) of numeric variable(s)."))
  
  for (i in 1:DPA_LinearlyDependentCount) {
    DPA_LinearlyDependentSubset <- colnames(DPA.Predictors.Numeric)[DPA_LinearlyDependent$linearCombos[[i]]]
    print(paste0("Linear dependent variable(s) for subset ",
                 i,
                 " include: ",
                 DPA_LinearlyDependentSubset))
  }
  
}

##################################
# Identifying the linearly dependent variables for removal
##################################

if (DPA_LinearlyDependentCount > 0) {
  DPA_LinearlyDependent <- findLinearCombos(DPA.Predictors.Numeric)
  
  DPA_LinearlyDependentForRemoval <- length(DPA_LinearlyDependent$remove)
  
  print(paste0("Linear dependency can be resolved by removing ",
               (DPA_LinearlyDependentForRemoval),
               " numeric variable(s)."))
  
  for (j in 1:DPA_LinearlyDependentForRemoval) {
  DPA_LinearlyDependentRemovedVariable <- colnames(DPA.Predictors.Numeric)[DPA_LinearlyDependent$remove[j]]
  print(paste0("Variable ",
               j,
               " for removal: ",
               DPA_LinearlyDependentRemovedVariable))
  }

}

```

</details>

###  1.3.5 Distributional Shape
|
| **[A]** No shape transformation was necessary as the distributional skewness observed among individual descriptors was normal (all values within +3 and -3) with minimal outliers.
|
|

<details><summary><mark style="background-color: #000000;color: #FFFFFF">**Code Chunk | Output**</mark></summary>

```{r section_1.3.5, warning=FALSE, message=FALSE, fig.width=15, fig.height=2}
##################################
# Distributional Shape
##################################

##################################
# Formulating the histogram
# for the numeric descriptors
##################################
for (i in 1:ncol(DPA.Descriptors.Numeric)) {
  Median <- format(round(median(DPA.Descriptors.Numeric[,i],na.rm = TRUE),2), nsmall=2)
  Mean <- format(round(mean(DPA.Descriptors.Numeric[,i],na.rm = TRUE),2), nsmall=2)
  Skewness <- format(round(skewness(DPA.Descriptors.Numeric[,i],na.rm = TRUE),2), nsmall=2)
  print(
  ggplot(DPA.Descriptors.Numeric, aes(x=DPA.Descriptors.Numeric[,i])) +
  geom_histogram(binwidth=1,color="black", fill="white") +
  geom_vline(aes(xintercept=mean(DPA.Descriptors.Numeric[,i])),
            color="blue", size=1) +
    geom_vline(aes(xintercept=median(DPA.Descriptors.Numeric[,i])),
            color="red", size=1) +
  theme_bw() +
  ylab("Count") +
  xlab(names(DPA.Descriptors.Numeric)[i]) +
  labs(title=names(DPA.Descriptors.Numeric)[i],
       subtitle=paste0("Median = ", Median,
                       ", Mean = ", Mean,
                       ", Skewness = ", Skewness)))
}

```

</details>

##  1.4 Data Pre-Assessment

###  1.4.1 Correlation Matrix Assessment - Covariance Validity
|
| **[A]** Covariance among descriptors in the correlation matrix was sufficient to justify the conduct of an exploratory factor analysis. 94% (62/66) of the pairwise associations using the Pearson correlation coefficient were above 30%.
|
|

<details><summary><mark style="background-color: #000000;color: #FFFFFF">**Code Chunk | Output**</mark></summary>

```{r section_1.4.1, warning=FALSE, message=FALSE}
##################################
# Identifying the minimally correlated variables
##################################
(DPA_MinimallyCorrelatedCount <- sum(abs(DPA_Correlation[upper.tri(DPA_Correlation)])>0.30))

(DPA_AllPairs <- length(DPA.Descriptors.Numeric)*(length(DPA.Descriptors.Numeric)-1)/2)

(DPA_MinimallyCorrelatedCountPercentage <- DPA_MinimallyCorrelatedCount/DPA_AllPairs)

qgraph(cor(DPA.Descriptors.Numeric),
       cut=0.30,
       details=TRUE,
       posCol="#2F75B5",
       negCol="#FF5050",
       labels=names(DPA.Descriptors.Numeric))

```

</details>

###  1.4.2 Correlation Matrix Assessment - Determinant Computation
|
| **[A]** The determinant of the correlation matrix was computed as 0.00002 (greater than .00001) indicating the absence of the likelihood for a multicollinearity problem. The results allowed for matrix operations to produce stable results during exploratory factor analysis.
|
|

<details><summary><mark style="background-color: #000000;color: #FFFFFF">**Code Chunk | Output**</mark></summary>

```{r section_1.4.2, warning=FALSE, message=FALSE}

##################################
# Computing the determinant of the correlation matrix
##################################
(DPA_CorrelationMatrixDeterminant <- det(cor(DPA.Descriptors.Numeric)))

```

</details>

###  1.4.3 Correlation Matrix Assessment - Bartlett’s Test of Sphericity
|
| **[A]** The computed p-value from the Bartlett’s Test of Sphericity was statistically significant (<0.00001), rejecting the null hypothesis that the correlation matrix is an identity matrix (ones on the diagonal and zeros on the off-diagonal). Results indicated that the correlation matrix is appropriate for exploratory factor analysis. 
|
|

<details><summary><mark style="background-color: #000000;color: #FFFFFF">**Code Chunk | Output**</mark></summary>

```{r section_1.4.3, warning=FALSE, message=FALSE}
##################################
# Calculating the Bartlett's Test of Sphericity
##################################
(DPA_BartlettTest <- cortest.bartlett(DPA.Descriptors.Numeric,
                                      n=nrow(DPA.Descriptors.Numeric)))

```

</details>

###  1.4.4 Correlation Matrix Assessment - Kaiser-Meyer-Olkin Factor Adequacy
|
| **[A]** The KMO measure of sampling adequacy was acceptable with a computed value of 0.798 for the complete model, indicating the suitability of the data for exploratory factor analysis. The estimated proportion of variance among all the observed variable was sufficiently adequate.
|
| **[B]**  The sampling adequacy for each variable in the model was acceptable with KMO values ranging from 0.676 to 0.883. Results indicated that each variable can be sufficiently predicted by other variables. 
|      **[B.1]** <span style="color: #FF0000">ACAD</span> = 0.847
|      **[B.2]** <span style="color: #FF0000">APPR</span> = 0.876
|      **[B.3]** <span style="color: #FF0000">COMM</span> = 0.790
|      **[B.4]** <span style="color: #FF0000">CFIT</span> = 0.809
|      **[B.5]** <span style="color: #FF0000">EXPR</span> = 0.782
|      **[B.6]** <span style="color: #FF0000">JFIT</span> = 0.827
|      **[B.7]** <span style="color: #FF0000">LETT</span> = 0.676
|      **[B.8]** <span style="color: #FF0000">LIKE</span> = 0.851
|      **[B.9]** <span style="color: #FF0000">ORGN</span> = 0.740
|      **[B.10]** <span style="color: #FF0000">POTL</span> = 0.883
|      **[B.11]** <span style="color: #FF0000">RESM</span> = 0.712
|      **[B.12]** <span style="color: #FF0000">SCON</span> = 0.777
|
|

<details><summary><mark style="background-color: #000000;color: #FFFFFF">**Code Chunk | Output**</mark></summary>

```{r section_1.4.4, warning=FALSE, message=FALSE}
##################################
# Calculating the Kaiser-Meyer-Olkin Factor Adequacy
##################################
(DPA_KMOFactorAdequacy <- KMO(DPA.Descriptors.Numeric))

```

</details>

###  1.4.5 Factor Retention - Maximum Consensus
|
|
|
|

<details><summary><mark style="background-color: #000000;color: #FFFFFF">**Code Chunk | Output**</mark></summary>

```{r section_1.4.5, warning=FALSE, message=FALSE}
##################################
# Implementing various procedures for determining
# factor retention based on
# the maximum consensus between methods
##################################
(DPA_MethodAgreementProcedure <- parameters::n_factors(DPA.Descriptors.Numeric))

as.data.frame(DPA_MethodAgreementProcedure)

```

</details>

## 1.5 Data Exploration
|
| Exploratory data analysis:
|
| **[A]** Critic and audience scores including their gaps from both sources were correlated.
|      **[A.1]** High <span style="color: #FF0000">Tomatometer_Critic</span> = High <span style="color: #FF0000">IMDB_Critic</span>
|      **[A.2]** High <span style="color: #FF0000">Tomatometer_Audience</span> = High <span style="color: #FF0000">IMDB_Audience</span>
|      **[A.3]** Low <span style="color: #FF0000">Tomatometer_Critic_Audience_Gap</span> = Low <span style="color: #FF0000">IMDB_Critic_Audience_Gap</span>
|
|

<details><summary><mark style="background-color: #000000;color: #FFFFFF">**Code Chunk | Output**</mark></summary>

```{r section_1.5, warning=FALSE, message=FALSE}
##################################
# Exploratory analysis
# among quantitative descriptors
##################################
splom(~DPA.Descriptors.Numeric,
      pch = 16,
      cex = 1,
      alpha = 0.45,
      auto.key = list(points = TRUE, space = "right"),
      main = "Exploratory Analysis Between Descriptors",
      xlab = "Scatterplot Matrix of Descriptors")

```

</details>

## 1.6 Factor Analysis

###  1.6.1 Principal Axes Factor Extraction and Varimax Rotation (FA_PA_V)
|
|
|
|

<details><summary><mark style="background-color: #000000;color: #FFFFFF">**Code Chunk | Output**</mark></summary>

```{r section_1.6.1, warning=FALSE, message=FALSE}
##################################
# Conducting exploratory factor analysis
# using Principal Axes extraction
# and Varimax rotation
# with 3 factors
##################################
(FA_PA_V_3F <- fa(DPA.Descriptors.Numeric,
              nfactors = 3,
              fm="pa",
              rotate = "varimax",
              residuals=TRUE,
              SMC=TRUE,
              n.obs=nrow(DPA.Descriptors.Numeric)))

(FA_PA_V_3F_Summary <- FA_PA_V_3F %>%
  model_parameters(sort = TRUE, threshold = "max"))

summary(FA_PA_V_3F_Summary)

##################################
# Extracting the residuals
# from the Exploratory Factor Analysis
##################################
(FA_PA_V_3F_Residual <- residuals(FA_PA_V_3F,
                              diag=FALSE,
                              na.rm=TRUE))

##################################
# Obtaining Fit Indices
##################################
(FA_PA_V_3F_RMS <- FA_PA_V_3F$rms)
(FA_PA_V_3F_TLI <- FA_PA_V_3F$TLI)
(FA_PA_V_3F_BIC <- FA_PA_V_3F$BIC)

(FA_PA_V_3F_MaxResidual   <- max(abs(FA_PA_V_3F_Residual),na.rm=TRUE))
(FA_PA_V_3F_HighResidual  <- sum(FA_PA_V_3F_Residual>abs(0.05),na.rm=TRUE))
(FA_PA_V_3F_TotalResidual <- length(DPA.Descriptors.Numeric)*(length(DPA.Descriptors.Numeric)-1)/2)
(FA_PA_V_3F_HighResidualRate <- FA_PA_V_3F_HighResidual/FA_PA_V_3F_TotalResidual)

##################################
# Graph the factor loading matrices
##################################
fa.diagram(FA_PA_V_3F,
           sort=TRUE,
           cut=0,
           digits=3,
           main="FA_PA_V",
           cex=0.75)

##################################
# computing the internal consistency
# measure of reliability using the
# Cronbach's alpha coefficient
# for each factor
##################################
alpha(DPA.Descriptors.Numeric[,c("ORGN","COMM","LIKE","APPR","SCON","CFIT")])
alpha(DPA.Descriptors.Numeric[,c("POTL","EXPR","ACAD","JFIT")])
alpha(DPA.Descriptors.Numeric[,c("LETT","RESM")])

##################################
# Formulating the dandelion plot to
# visualize both factor variances and loadings
# from the factor loading matrices
##################################
FA_PA_V_3F_FactorLoading <- factload(DPA.Descriptors.Numeric,
                                  cormeth = "pearson",
                                  method = "prax",
                                  nfac = 3,
                                  rotation = "varimax")

DandelionPlotPalette <- rev(rainbow(100, start = 0, end = 0.2))

dandelion(FA_PA_V_3F_FactorLoading,
          bound=0,
          mcex=c(1,1.2),
          palet=DandelionPlotPalette)

##################################
# Conducting exploratory factor analysis
# using Principal Axes extraction
# and Varimax rotation
# with 4 factors
##################################
(FA_PA_V_4F <- fa(DPA.Descriptors.Numeric,
              nfactors = 4,
              fm="pa",
              rotate = "varimax",
              residuals=TRUE,
              SMC=TRUE,
              n.obs=nrow(DPA.Descriptors.Numeric)))

(FA_PA_V_4F_Summary <- FA_PA_V_4F %>%
  model_parameters(sort = TRUE, threshold = "max"))

summary(FA_PA_V_4F_Summary)

##################################
# Extracting the residuals
# from the Exploratory Factor Analysis
##################################
(FA_PA_V_4F_Residual <- residuals(FA_PA_V_4F,
                              diag=FALSE,
                              na.rm=TRUE))

##################################
# Obtaining Fit Indices
##################################
(FA_PA_V_4F_RMS <- FA_PA_V_4F$rms)
(FA_PA_V_4F_TLI <- FA_PA_V_4F$TLI)
(FA_PA_V_4F_BIC <- FA_PA_V_4F$BIC)

(FA_PA_V_4F_MaxResidual   <- max(abs(FA_PA_V_4F_Residual),na.rm=TRUE))
(FA_PA_V_4F_HighResidual  <- sum(FA_PA_V_4F_Residual>abs(0.05),na.rm=TRUE))
(FA_PA_V_4F_TotalResidual <- length(DPA.Descriptors.Numeric)*(length(DPA.Descriptors.Numeric)-1)/2)
(FA_PA_V_4F_HighResidualRate <- FA_PA_V_4F_HighResidual/FA_PA_V_4F_TotalResidual)

##################################
# Graph the factor loading matrices
##################################
fa.diagram(FA_PA_V_4F,
           sort=TRUE,
           cut=0,
           digits=3,
           main="FA_PA_V",
           cex=0.75)

##################################
# computing the internal consistency
# measure of reliability using the
# Cronbach's alpha coefficient
# for each factor
##################################
alpha(DPA.Descriptors.Numeric[,c("POTL","EXPR","ACAD","JFIT")])
alpha(DPA.Descriptors.Numeric[,c("ORGN","COMM","CFIT")])
alpha(DPA.Descriptors.Numeric[,c("SCON","APPR","LIKE")])
alpha(DPA.Descriptors.Numeric[,c("LETT","RESM")])

##################################
# Formulating the dandelion plot to
# visualize both factor variances and loadings
# from the factor loading matrices
##################################
FA_PA_V_4F_FactorLoading <- factload(DPA.Descriptors.Numeric,
                                  cormeth = "pearson",
                                  method = "prax",
                                  nfac = 4,
                                  rotation = "varimax")

DandelionPlotPalette <- rev(rainbow(100, start = 0, end = 0.2))

dandelion(FA_PA_V_4F_FactorLoading,
          bound=0,
          mcex=c(1,1.2),
          palet=DandelionPlotPalette)

##################################
# Conducting exploratory factor analysis
# using Principal Axes extraction
# and Varimax rotation
# with 5 factors
##################################
(FA_PA_V_5F <- fa(DPA.Descriptors.Numeric,
              nfactors = 5,
              fm="pa",
              rotate = "varimax",
              residuals=TRUE,
              SMC=TRUE,
              n.obs=nrow(DPA.Descriptors.Numeric)))

(FA_PA_V_5F_Summary <- FA_PA_V_5F %>%
  model_parameters(sort = TRUE, threshold = "max"))

summary(FA_PA_V_5F_Summary)

##################################
# Extracting the residuals
# from the Exploratory Factor Analysis
##################################
(FA_PA_V_5F_Residual <- residuals(FA_PA_V_5F,
                              diag=FALSE,
                              na.rm=TRUE))

##################################
# Obtaining Fit Indices
##################################
(FA_PA_V_5F_RMS <- FA_PA_V_5F$rms)
(FA_PA_V_5F_TLI <- FA_PA_V_5F$TLI)
(FA_PA_V_5F_BIC <- FA_PA_V_5F$BIC)

(FA_PA_V_5F_MaxResidual   <- max(abs(FA_PA_V_5F_Residual),na.rm=TRUE))
(FA_PA_V_5F_HighResidual  <- sum(FA_PA_V_5F_Residual>abs(0.05),na.rm=TRUE))
(FA_PA_V_5F_TotalResidual <- length(DPA.Descriptors.Numeric)*(length(DPA.Descriptors.Numeric)-1)/2)
(FA_PA_V_5F_HighResidualRate <- FA_PA_V_5F_HighResidual/FA_PA_V_5F_TotalResidual)

##################################
# Graph the factor loading matrices
##################################
fa.diagram(FA_PA_V_5F,
           sort=TRUE,
           cut=0,
           digits=3,
           main="FA_PA_V",
           cex=0.75)

##################################
# computing the internal consistency
# measure of reliability using the
# Cronbach's alpha coefficient
# for each factor
##################################
alpha(DPA.Descriptors.Numeric[,c("ACAD","POTL","EXPR")])
alpha(DPA.Descriptors.Numeric[,c("SCON","LIKE","APPR")])
alpha(DPA.Descriptors.Numeric[,c("COMM","ORGN")])
alpha(DPA.Descriptors.Numeric[,c("LETT","RESM")])
alpha(DPA.Descriptors.Numeric[,c("JFIT","CFIT")])

##################################
# Formulating the dandelion plot to
# visualize both factor variances and loadings
# from the factor loading matrices
##################################
FA_PA_V_5F_FactorLoading <- factload(DPA.Descriptors.Numeric,
                                  cormeth = "pearson",
                                  method = "prax",
                                  nfac = 5,
                                  rotation = "varimax")

DandelionPlotPalette <- rev(rainbow(100, start = 0, end = 0.2))

dandelion(FA_PA_V_5F_FactorLoading,
          bound=0,
          mcex=c(1,1.2),
          palet=DandelionPlotPalette)

par(mfrow=c(1,3))
fa.diagram(FA_PA_V_3F,
           sort=TRUE,
           cut=0,
           digits=3,
           main="FA_PA_V : 3 Factors",
           cex=0.75)
fa.diagram(FA_PA_V_4F,
           sort=TRUE,
           cut=0,
           digits=3,
           main="FA_PA_V : 4 Factors",
           cex=0.75)
fa.diagram(FA_PA_V_5F,
           sort=TRUE,
           cut=0,
           digits=3,
           main="FA_PA_V : 5 Factors",
           cex=0.75)

```

</details>

###  1.6.2 Principal Axes Factor Extraction and Promax Rotation (FA_PA_P)
|
|
|
|

<details><summary><mark style="background-color: #000000;color: #FFFFFF">**Code Chunk | Output**</mark></summary>

```{r section_1.6.2, warning=FALSE, message=FALSE}
##################################
# Conducting exploratory factor analysis
# using Principal Axes extraction
# and Promax rotation
# with 3 factors
##################################
(FA_PA_P_3F <- fa(DPA.Descriptors.Numeric,
              nfactors = 3,
              fm="pa",
              rotate = "promax",
              residuals=TRUE,
              SMC=TRUE,
              n.obs=nrow(DPA.Descriptors.Numeric)))

(FA_PA_P_3F_Summary <- FA_PA_P_3F %>%
  model_parameters(sort = TRUE, threshold = "max"))

summary(FA_PA_P_3F_Summary)

##################################
# Extracting the residuals
# from the Exploratory Factor Analysis
##################################
(FA_PA_P_3F_Residual <- residuals(FA_PA_P_3F,
                              diag=FALSE,
                              na.rm=TRUE))

##################################
# Obtaining Fit Indices
##################################
(FA_PA_P_3F_RMS <- FA_PA_P_3F$rms)
(FA_PA_P_3F_TLI <- FA_PA_P_3F$TLI)
(FA_PA_P_3F_BIC <- FA_PA_P_3F$BIC)

(FA_PA_P_3F_MaxResidual   <- max(abs(FA_PA_P_3F_Residual),na.rm=TRUE))
(FA_PA_P_3F_HighResidual  <- sum(FA_PA_P_3F_Residual>abs(0.05),na.rm=TRUE))
(FA_PA_P_3F_TotalResidual <- length(DPA.Descriptors.Numeric)*(length(DPA.Descriptors.Numeric)-1)/2)
(FA_PA_P_3F_HighResidualRate <- FA_PA_P_3F_HighResidual/FA_PA_P_3F_TotalResidual)

##################################
# Graph the factor loading matrices
##################################
fa.diagram(FA_PA_P_3F,
           sort=TRUE,
           cut=0,
           digits=3,
           main="FA_PA_V",
           cex=0.75)

##################################
# computing the internal consistency
# measure of reliability using the
# Cronbach's alpha coefficient
# for each factor
##################################
alpha(DPA.Descriptors.Numeric[,c("ORGN","COMM","LIKE","APPR","SCON","CFIT")])
alpha(DPA.Descriptors.Numeric[,c("POTL","EXPR","ACAD","JFIT")])
alpha(DPA.Descriptors.Numeric[,c("LETT","RESM")])

##################################
# Formulating the dandelion plot to
# visualize both factor variances and loadings
# from the factor loading matrices
##################################
FA_PA_P_3F_FactorLoading <- factload(DPA.Descriptors.Numeric,
                                  cormeth = "pearson",
                                  method = "prax",
                                  nfac = 3,
                                  rotation = "promax")

DandelionPlotPalette <- rev(rainbow(100, start = 0, end = 0.2))

dandelion(FA_PA_P_3F_FactorLoading,
          bound=0,
          mcex=c(1,1.2),
          palet=DandelionPlotPalette)

##################################
# Conducting exploratory factor analysis
# using Principal Axes extraction
# and Promax rotation
# with 4 factors
##################################
(FA_PA_P_4F <- fa(DPA.Descriptors.Numeric,
              nfactors = 4,
              fm="pa",
              rotate = "promax",
              residuals=TRUE,
              SMC=TRUE,
              n.obs=nrow(DPA.Descriptors.Numeric)))

(FA_PA_P_4F_Summary <- FA_PA_P_4F %>%
  model_parameters(sort = TRUE, threshold = "max"))

summary(FA_PA_P_4F_Summary)

##################################
# Extracting the residuals
# from the Exploratory Factor Analysis
##################################
(FA_PA_P_4F_Residual <- residuals(FA_PA_P_4F,
                              diag=FALSE,
                              na.rm=TRUE))

##################################
# Obtaining Fit Indices
##################################
(FA_PA_P_4F_RMS <- FA_PA_P_4F$rms)
(FA_PA_P_4F_TLI <- FA_PA_P_4F$TLI)
(FA_PA_P_4F_BIC <- FA_PA_P_4F$BIC)

(FA_PA_P_4F_MaxResidual   <- max(abs(FA_PA_P_4F_Residual),na.rm=TRUE))
(FA_PA_P_4F_HighResidual  <- sum(FA_PA_P_4F_Residual>abs(0.05),na.rm=TRUE))
(FA_PA_P_4F_TotalResidual <- length(DPA.Descriptors.Numeric)*(length(DPA.Descriptors.Numeric)-1)/2)
(FA_PA_P_4F_HighResidualRate <- FA_PA_P_4F_HighResidual/FA_PA_P_4F_TotalResidual)

##################################
# Graph the factor loading matrices
##################################
fa.diagram(FA_PA_P_4F,
           sort=TRUE,
           cut=0,
           digits=3,
           main="FA_PA_V",
           cex=0.75)

##################################
# computing the internal consistency
# measure of reliability using the
# Cronbach's alpha coefficient
# for each factor
##################################
alpha(DPA.Descriptors.Numeric[,c("POTL","EXPR","ACAD","JFIT")])
alpha(DPA.Descriptors.Numeric[,c("ORGN","COMM","CFIT")])
alpha(DPA.Descriptors.Numeric[,c("SCON","APPR","LIKE")])
alpha(DPA.Descriptors.Numeric[,c("LETT","RESM")])

##################################
# Formulating the dandelion plot to
# visualize both factor variances and loadings
# from the factor loading matrices
##################################
FA_PA_P_4F_FactorLoading <- factload(DPA.Descriptors.Numeric,
                                  cormeth = "pearson",
                                  method = "prax",
                                  nfac = 4,
                                  rotation = "promax")

DandelionPlotPalette <- rev(rainbow(100, start = 0, end = 0.2))

dandelion(FA_PA_P_4F_FactorLoading,
          bound=0,
          mcex=c(1,1.2),
          palet=DandelionPlotPalette)

##################################
# Conducting exploratory factor analysis
# using Principal Axes extraction
# and Promax rotation
# with 5 factors
##################################
(FA_PA_P_5F <- fa(DPA.Descriptors.Numeric,
              nfactors = 5,
              fm="pa",
              rotate = "promax",
              residuals=TRUE,
              SMC=TRUE,
              n.obs=nrow(DPA.Descriptors.Numeric)))

(FA_PA_P_5F_Summary <- FA_PA_P_5F %>%
  model_parameters(sort = TRUE, threshold = "max"))

summary(FA_PA_P_5F_Summary)

##################################
# Extracting the residuals
# from the Exploratory Factor Analysis
##################################
(FA_PA_P_5F_Residual <- residuals(FA_PA_P_5F,
                              diag=FALSE,
                              na.rm=TRUE))

##################################
# Obtaining Fit Indices
##################################
(FA_PA_P_5F_RMS <- FA_PA_P_5F$rms)
(FA_PA_P_5F_TLI <- FA_PA_P_5F$TLI)
(FA_PA_P_5F_BIC <- FA_PA_P_5F$BIC)

(FA_PA_P_5F_MaxResidual   <- max(abs(FA_PA_P_5F_Residual),na.rm=TRUE))
(FA_PA_P_5F_HighResidual  <- sum(FA_PA_P_5F_Residual>abs(0.05),na.rm=TRUE))
(FA_PA_P_5F_TotalResidual <- length(DPA.Descriptors.Numeric)*(length(DPA.Descriptors.Numeric)-1)/2)
(FA_PA_P_5F_HighResidualRate <- FA_PA_P_5F_HighResidual/FA_PA_P_5F_TotalResidual)

##################################
# Graph the factor loading matrices
##################################
fa.diagram(FA_PA_P_5F,
           sort=TRUE,
           cut=0,
           digits=3,
           main="FA_PA_V",
           cex=0.75)

##################################
# computing the internal consistency
# measure of reliability using the
# Cronbach's alpha coefficient
# for each factor
##################################
alpha(DPA.Descriptors.Numeric[,c("ACAD","POTL","EXPR")])
alpha(DPA.Descriptors.Numeric[,c("SCON","LIKE","APPR")])
alpha(DPA.Descriptors.Numeric[,c("COMM","ORGN")])
alpha(DPA.Descriptors.Numeric[,c("LETT","RESM")])
alpha(DPA.Descriptors.Numeric[,c("JFIT","CFIT")])

##################################
# Formulating the dandelion plot to
# visualize both factor variances and loadings
# from the factor loading matrices
##################################
FA_PA_P_5F_FactorLoading <- factload(DPA.Descriptors.Numeric,
                                  cormeth = "pearson",
                                  method = "prax",
                                  nfac = 5,
                                  rotation = "promax")

DandelionPlotPalette <- rev(rainbow(100, start = 0, end = 0.2))

dandelion(FA_PA_P_5F_FactorLoading,
          bound=0,
          mcex=c(1,1.2),
          palet=DandelionPlotPalette)

par(mfrow=c(1,3))
fa.diagram(FA_PA_P_3F,
           sort=TRUE,
           cut=0,
           digits=3,
           main="FA_PA_P : 3 Factors",
           cex=0.75)
fa.diagram(FA_PA_P_4F,
           sort=TRUE,
           cut=0,
           digits=3,
           main="FA_PA_P : 4 Factors",
           cex=0.75)
fa.diagram(FA_PA_P_5F,
           sort=TRUE,
           cut=0,
           digits=3,
           main="FA_PA_P : 5 Factors",
           cex=0.75)

```

</details>

###  1.6.3 Maximum Likelihood Factor Extraction and Varimax Rotation (FA_ML_V)
|
|
|
|

<details><summary><mark style="background-color: #000000;color: #FFFFFF">**Code Chunk | Output**</mark></summary>

```{r section_1.6.3, warning=FALSE, message=FALSE}
##################################
# Conducting exploratory factor analysis
# using Maximum Likelihood extraction
# and Varimax rotation
# with 3 factors
##################################
(FA_ML_V_3F <- fa(DPA.Descriptors.Numeric,
              nfactors = 3,
              fm="ml",
              rotate = "varimax",
              residuals=TRUE,
              SMC=TRUE,
              n.obs=nrow(DPA.Descriptors.Numeric)))

(FA_ML_V_3F_Summary <- FA_ML_V_3F %>%
  model_parameters(sort = TRUE, threshold = "max"))

summary(FA_ML_V_3F_Summary)

##################################
# Extracting the residuals
# from the Exploratory Factor Analysis
##################################
(FA_ML_V_3F_Residual <- residuals(FA_ML_V_3F,
                              diag=FALSE,
                              na.rm=TRUE))

##################################
# Obtaining Fit Indices
##################################
(FA_ML_V_3F_RMS <- FA_ML_V_3F$rms)
(FA_ML_V_3F_TLI <- FA_ML_V_3F$TLI)
(FA_ML_V_3F_BIC <- FA_ML_V_3F$BIC)

(FA_ML_V_3F_MaxResidual   <- max(abs(FA_ML_V_3F_Residual),na.rm=TRUE))
(FA_ML_V_3F_HighResidual  <- sum(FA_ML_V_3F_Residual>abs(0.05),na.rm=TRUE))
(FA_ML_V_3F_TotalResidual <- length(DPA.Descriptors.Numeric)*(length(DPA.Descriptors.Numeric)-1)/2)
(FA_ML_V_3F_HighResidualRate <- FA_ML_V_3F_HighResidual/FA_ML_V_3F_TotalResidual)

##################################
# Graph the factor loading matrices
##################################
fa.diagram(FA_ML_V_3F,
           sort=TRUE,
           cut=0,
           digits=3,
           main="FA_ML_V",
           cex=0.75)

##################################
# computing the internal consistency
# measure of reliability using the
# Cronbach's alpha coefficient
# for each factor
##################################
alpha(DPA.Descriptors.Numeric[,c("POTL","ACAD","EXPR","JFIT")])
alpha(DPA.Descriptors.Numeric[,c("ORGN","COMM","LIKE","APPR","SCON","CFIT")])
alpha(DPA.Descriptors.Numeric[,c("RESM","LETT")])

##################################
# Formulating the dandelion plot to
# visualize both factor variances and loadings
# from the factor loading matrices
##################################
FA_ML_V_3F_FactorLoading <- factload(DPA.Descriptors.Numeric,
                                  cormeth = "pearson",
                                  method = "mle",
                                  nfac = 3,
                                  rotation = "varimax")

DandelionPlotPalette <- rev(rainbow(100, start = 0, end = 0.2))

dandelion(FA_ML_V_3F_FactorLoading,
          bound=0,
          mcex=c(1,1.2),
          palet=DandelionPlotPalette)

##################################
# Conducting exploratory factor analysis
# using Maximum Likelihood extraction
# and Varimax rotation
# with 4 factors
##################################
(FA_ML_V_4F <- fa(DPA.Descriptors.Numeric,
              nfactors = 4,
              fm="ml",
              rotate = "varimax",
              residuals=TRUE,
              SMC=TRUE,
              n.obs=nrow(DPA.Descriptors.Numeric)))

(FA_ML_V_4F_Summary <- FA_ML_V_4F %>%
  model_parameters(sort = TRUE, threshold = "max"))

summary(FA_ML_V_4F_Summary)

##################################
# Extracting the residuals
# from the Exploratory Factor Analysis
##################################
(FA_ML_V_4F_Residual <- residuals(FA_ML_V_4F,
                              diag=FALSE,
                              na.rm=TRUE))

##################################
# Obtaining Fit Indices
##################################
(FA_ML_V_4F_RMS <- FA_ML_V_4F$rms)
(FA_ML_V_4F_TLI <- FA_ML_V_4F$TLI)
(FA_ML_V_4F_BIC <- FA_ML_V_4F$BIC)

(FA_ML_V_4F_MaxResidual   <- max(abs(FA_ML_V_4F_Residual),na.rm=TRUE))
(FA_ML_V_4F_HighResidual  <- sum(FA_ML_V_4F_Residual>abs(0.05),na.rm=TRUE))
(FA_ML_V_4F_TotalResidual <- length(DPA.Descriptors.Numeric)*(length(DPA.Descriptors.Numeric)-1)/2)
(FA_ML_V_4F_HighResidualRate <- FA_ML_V_4F_HighResidual/FA_ML_V_4F_TotalResidual)

##################################
# Graph the factor loading matrices
##################################
fa.diagram(FA_ML_V_4F,
           sort=TRUE,
           cut=0,
           digits=3,
           main="FA_ML_V",
           cex=0.75)

##################################
# computing the internal consistency
# measure of reliability using the
# Cronbach's alpha coefficient
# for each factor
##################################
alpha(DPA.Descriptors.Numeric[,c("JFIT","CFIT","POTL","EXPR","ACAD")])
alpha(DPA.Descriptors.Numeric[,c("SCON","APPR","LIKE")])
alpha(DPA.Descriptors.Numeric[,c("ORGN","COMM")])
alpha(DPA.Descriptors.Numeric[,c("RESM","LETT")])

##################################
# Formulating the dandelion plot to
# visualize both factor variances and loadings
# from the factor loading matrices
##################################
FA_ML_V_4F_FactorLoading <- factload(DPA.Descriptors.Numeric,
                                  cormeth = "pearson",
                                  method = "mle",
                                  nfac = 4,
                                  rotation = "varimax")

DandelionPlotPalette <- rev(rainbow(100, start = 0, end = 0.2))

dandelion(FA_ML_V_4F_FactorLoading,
          bound=0,
          mcex=c(1,1.2),
          palet=DandelionPlotPalette)

##################################
# Conducting exploratory factor analysis
# using Maximum Likelihood extraction
# and Varimax rotation
# with 5 factors
##################################
(FA_ML_V_5F <- fa(DPA.Descriptors.Numeric,
              nfactors = 5,
              fm="ml",
              rotate = "varimax",
              residuals=TRUE,
              SMC=TRUE,
              n.obs=nrow(DPA.Descriptors.Numeric)))

(FA_ML_V_5F_Summary <- FA_ML_V_5F %>%
  model_parameters(sort = TRUE, threshold = "max"))

summary(FA_ML_V_5F_Summary)

##################################
# Extracting the residuals
# from the Exploratory Factor Analysis
##################################
(FA_ML_V_5F_Residual <- residuals(FA_ML_V_5F,
                              diag=FALSE,
                              na.rm=TRUE))

##################################
# Obtaining Fit Indices
##################################
(FA_ML_V_5F_RMS <- FA_ML_V_5F$rms)
(FA_ML_V_5F_TLI <- FA_ML_V_5F$TLI)
(FA_ML_V_5F_BIC <- FA_ML_V_5F$BIC)

(FA_ML_V_5F_MaxResidual   <- max(abs(FA_ML_V_5F_Residual),na.rm=TRUE))
(FA_ML_V_5F_HighResidual  <- sum(FA_ML_V_5F_Residual>abs(0.05),na.rm=TRUE))
(FA_ML_V_5F_TotalResidual <- length(DPA.Descriptors.Numeric)*(length(DPA.Descriptors.Numeric)-1)/2)
(FA_ML_V_5F_HighResidualRate <- FA_ML_V_5F_HighResidual/FA_ML_V_5F_TotalResidual)

##################################
# Graph the factor loading matrices
##################################
fa.diagram(FA_ML_V_5F,
           sort=TRUE,
           cut=0,
           digits=3,
           main="FA_ML_V",
           cex=0.75)

##################################
# computing the internal consistency
# measure of reliability using the
# Cronbach's alpha coefficient
# for each factor
##################################
alpha(DPA.Descriptors.Numeric[,c("ACAD","POTL","EXPR")])
alpha(DPA.Descriptors.Numeric[,c("SCON","LIKE","APPR")])
alpha(DPA.Descriptors.Numeric[,c("ORGN","COMM")])
alpha(DPA.Descriptors.Numeric[,c("RESM","LETT")])
alpha(DPA.Descriptors.Numeric[,c("JFIT","CFIT")])

##################################
# Formulating the dandelion plot to
# visualize both factor variances and loadings
# from the factor loading matrices
##################################
FA_ML_V_5F_FactorLoading <- factload(DPA.Descriptors.Numeric,
                                  cormeth = "pearson",
                                  method = "mle",
                                  nfac = 5,
                                  rotation = "varimax")

DandelionPlotPalette <- rev(rainbow(100, start = 0, end = 0.2))

dandelion(FA_ML_V_5F_FactorLoading,
          bound=0,
          mcex=c(1,1.2),
          palet=DandelionPlotPalette)

par(mfrow=c(1,3))
fa.diagram(FA_ML_V_3F,
           sort=TRUE,
           cut=0,
           digits=3,
           main="FA_ML_V : 3 Factors",
           cex=0.75)
fa.diagram(FA_ML_V_4F,
           sort=TRUE,
           cut=0,
           digits=3,
           main="FA_ML_V : 4 Factors",
           cex=0.75)
fa.diagram(FA_ML_V_5F,
           sort=TRUE,
           cut=0,
           digits=3,
           main="FA_ML_V : 5 Factors",
           cex=0.75)

```

</details>

###  1.6.4 Maximum Likelihood Factor Extraction and Promax Rotation (FA_ML_P)
|
|
|
|

<details><summary><mark style="background-color: #000000;color: #FFFFFF">**Code Chunk | Output**</mark></summary>

```{r section_1.6.4, warning=FALSE, message=FALSE}
##################################
# Conducting exploratory factor analysis
# using Maximum Likelihood extraction
# and Promax rotation
# with 3 factors
##################################
(FA_ML_P_3F <- fa(DPA.Descriptors.Numeric,
              nfactors = 3,
              fm="ml",
              rotate = "promax",
              residuals=TRUE,
              SMC=TRUE,
              n.obs=nrow(DPA.Descriptors.Numeric)))

(FA_ML_P_3F_Summary <- FA_ML_P_3F %>%
  model_parameters(sort = TRUE, threshold = "max"))

summary(FA_ML_P_3F_Summary)

##################################
# Extracting the residuals
# from the Exploratory Factor Analysis
##################################
(FA_ML_P_3F_Residual <- residuals(FA_ML_P_3F,
                              diag=FALSE,
                              na.rm=TRUE))

##################################
# Obtaining Fit Indices
##################################
(FA_ML_P_3F_RMS <- FA_ML_P_3F$rms)
(FA_ML_P_3F_TLI <- FA_ML_P_3F$TLI)
(FA_ML_P_3F_BIC <- FA_ML_P_3F$BIC)

(FA_ML_P_3F_MaxResidual   <- max(abs(FA_ML_P_3F_Residual),na.rm=TRUE))
(FA_ML_P_3F_HighResidual  <- sum(FA_ML_P_3F_Residual>abs(0.05),na.rm=TRUE))
(FA_ML_P_3F_TotalResidual <- length(DPA.Descriptors.Numeric)*(length(DPA.Descriptors.Numeric)-1)/2)
(FA_ML_P_3F_HighResidualRate <- FA_ML_P_3F_HighResidual/FA_ML_P_3F_TotalResidual)

##################################
# Graph the factor loading matrices
##################################
fa.diagram(FA_ML_P_3F,
           sort=TRUE,
           cut=0,
           digits=3,
           main="FA_ML_P",
           cex=0.75)

##################################
# computing the internal consistency
# measure of reliability using the
# Cronbach's alpha coefficient
# for each factor
##################################
alpha(DPA.Descriptors.Numeric[,c("POTL","ACAD","EXPR","JFIT")])
alpha(DPA.Descriptors.Numeric[,c("ORGN","COMM","LIKE","APPR","SCON","CFIT")])
alpha(DPA.Descriptors.Numeric[,c("RESM","LETT")])

##################################
# Formulating the dandelion plot to
# visualize both factor variances and loadings
# from the factor loading matrices
##################################
FA_ML_P_3F_FactorLoading <- factload(DPA.Descriptors.Numeric,
                                  cormeth = "pearson",
                                  method = "mle",
                                  nfac = 3,
                                  rotation = "promax")

DandelionPlotPalette <- rev(rainbow(100, start = 0, end = 0.2))

dandelion(FA_ML_P_3F_FactorLoading,
          bound=0,
          mcex=c(1,1.2),
          palet=DandelionPlotPalette)

##################################
# Conducting exploratory factor analysis
# using Maximum Likelihood extraction
# and Promax rotation
# with 4 factors
##################################
(FA_ML_P_4F <- fa(DPA.Descriptors.Numeric,
              nfactors = 4,
              fm="ml",
              rotate = "promax",
              residuals=TRUE,
              SMC=TRUE,
              n.obs=nrow(DPA.Descriptors.Numeric)))

(FA_ML_P_4F_Summary <- FA_ML_P_4F %>%
  model_parameters(sort = TRUE, threshold = "max"))

summary(FA_ML_P_4F_Summary)

##################################
# Extracting the residuals
# from the Exploratory Factor Analysis
##################################
(FA_ML_P_4F_Residual <- residuals(FA_ML_P_4F,
                              diag=FALSE,
                              na.rm=TRUE))

##################################
# Obtaining Fit Indices
##################################
(FA_ML_P_4F_RMS <- FA_ML_P_4F$rms)
(FA_ML_P_4F_TLI <- FA_ML_P_4F$TLI)
(FA_ML_P_4F_BIC <- FA_ML_P_4F$BIC)

(FA_ML_P_4F_MaxResidual   <- max(abs(FA_ML_P_4F_Residual),na.rm=TRUE))
(FA_ML_P_4F_HighResidual  <- sum(FA_ML_P_4F_Residual>abs(0.05),na.rm=TRUE))
(FA_ML_P_4F_TotalResidual <- length(DPA.Descriptors.Numeric)*(length(DPA.Descriptors.Numeric)-1)/2)
(FA_ML_P_4F_HighResidualRate <- FA_ML_P_4F_HighResidual/FA_ML_P_4F_TotalResidual)

##################################
# Graph the factor loading matrices
##################################
fa.diagram(FA_ML_P_4F,
           sort=TRUE,
           cut=0,
           digits=3,
           main="FA_ML_P",
           cex=0.75)

##################################
# computing the internal consistency
# measure of reliability using the
# Cronbach's alpha coefficient
# for each factor
##################################
alpha(DPA.Descriptors.Numeric[,c("JFIT","CFIT","POTL","EXPR","ACAD")])
alpha(DPA.Descriptors.Numeric[,c("SCON","APPR","LIKE")])
alpha(DPA.Descriptors.Numeric[,c("ORGN","COMM")])
alpha(DPA.Descriptors.Numeric[,c("RESM","LETT")])

##################################
# Formulating the dandelion plot to
# visualize both factor variances and loadings
# from the factor loading matrices
##################################
FA_ML_P_4F_FactorLoading <- factload(DPA.Descriptors.Numeric,
                                  cormeth = "pearson",
                                  method = "mle",
                                  nfac = 4,
                                  rotation = "promax")

DandelionPlotPalette <- rev(rainbow(100, start = 0, end = 0.2))

dandelion(FA_ML_P_4F_FactorLoading,
          bound=0,
          mcex=c(1,1.2),
          palet=DandelionPlotPalette)

##################################
# Conducting exploratory factor analysis
# using Maximum Likelihood extraction
# and Promax rotation
# with 5 factors
##################################
(FA_ML_P_5F <- fa(DPA.Descriptors.Numeric,
              nfactors = 5,
              fm="ml",
              rotate = "promax",
              residuals=TRUE,
              SMC=TRUE,
              n.obs=nrow(DPA.Descriptors.Numeric)))

(FA_ML_P_5F_Summary <- FA_ML_P_5F %>%
  model_parameters(sort = TRUE, threshold = "max"))

summary(FA_ML_P_5F_Summary)

##################################
# Extracting the residuals
# from the Exploratory Factor Analysis
##################################
(FA_ML_P_5F_Residual <- residuals(FA_ML_P_5F,
                              diag=FALSE,
                              na.rm=TRUE))

##################################
# Obtaining Fit Indices
##################################
(FA_ML_P_5F_RMS <- FA_ML_P_5F$rms)
(FA_ML_P_5F_TLI <- FA_ML_P_5F$TLI)
(FA_ML_P_5F_BIC <- FA_ML_P_5F$BIC)

(FA_ML_P_5F_MaxResidual   <- max(abs(FA_ML_P_5F_Residual),na.rm=TRUE))
(FA_ML_P_5F_HighResidual  <- sum(FA_ML_P_5F_Residual>abs(0.05),na.rm=TRUE))
(FA_ML_P_5F_TotalResidual <- length(DPA.Descriptors.Numeric)*(length(DPA.Descriptors.Numeric)-1)/2)
(FA_ML_P_5F_HighResidualRate <- FA_ML_P_5F_HighResidual/FA_ML_P_5F_TotalResidual)

##################################
# Graph the factor loading matrices
##################################
fa.diagram(FA_ML_P_5F,
           sort=TRUE,
           cut=0,
           digits=3,
           main="FA_ML_P",
           cex=0.75)

##################################
# computing the internal consistency
# measure of reliability using the
# Cronbach's alpha coefficient
# for each factor
##################################
alpha(DPA.Descriptors.Numeric[,c("ACAD","POTL","EXPR")])
alpha(DPA.Descriptors.Numeric[,c("SCON","LIKE","APPR")])
alpha(DPA.Descriptors.Numeric[,c("ORGN","COMM")])
alpha(DPA.Descriptors.Numeric[,c("RESM","LETT")])
alpha(DPA.Descriptors.Numeric[,c("JFIT","CFIT")])

##################################
# Formulating the dandelion plot to
# visualize both factor variances and loadings
# from the factor loading matrices
##################################
FA_ML_P_5F_FactorLoading <- factload(DPA.Descriptors.Numeric,
                                  cormeth = "pearson",
                                  method = "mle",
                                  nfac = 5,
                                  rotation = "promax")

DandelionPlotPalette <- rev(rainbow(100, start = 0, end = 0.2))

dandelion(FA_ML_P_5F_FactorLoading,
          bound=0,
          mcex=c(1,1.2),
          palet=DandelionPlotPalette)

par(mfrow=c(1,3))
fa.diagram(FA_ML_P_3F,
           sort=TRUE,
           cut=0,
           digits=3,
           main="FA_ML_P : 3 Factors",
           cex=0.75)
fa.diagram(FA_ML_P_4F,
           sort=TRUE,
           cut=0,
           digits=3,
           main="FA_ML_P : 4 Factors",
           cex=0.75)
fa.diagram(FA_ML_P_5F,
           sort=TRUE,
           cut=0,
           digits=3,
           main="FA_ML_P : 5 Factors",
           cex=0.75)

```

</details>


##  1.7 Algorithm Comparison Summary
|
|

<details><summary><mark style="background-color: #000000;color: #FFFFFF">**Code Chunk | Output**</mark></summary>

```{r section_1.6, warning=FALSE, message=FALSE, dev='png'}

##################################
# Consolidating the fit indices
##################################
FA_RMSSummary <- c(FA_PA_V_3F_RMS,
                   FA_PA_V_4F_RMS,
                   FA_PA_V_5F_RMS,
                   FA_PA_P_3F_RMS,
                   FA_PA_P_4F_RMS,
                   FA_PA_P_5F_RMS,
                   FA_ML_V_3F_RMS,
                   FA_ML_V_4F_RMS,
                   FA_ML_V_5F_RMS,
                   FA_ML_P_3F_RMS,
                   FA_ML_P_4F_RMS,
                   FA_ML_P_5F_RMS)

FA_TLISummary <- c(FA_PA_V_3F_TLI,
                   FA_PA_V_4F_TLI,
                   FA_PA_V_5F_TLI,
                   FA_PA_P_3F_TLI,
                   FA_PA_P_4F_TLI,
                   FA_PA_P_5F_TLI,
                   FA_ML_V_3F_TLI,
                   FA_ML_V_4F_TLI,
                   FA_ML_V_5F_TLI,
                   FA_ML_P_3F_TLI,
                   FA_ML_P_4F_TLI,
                   FA_ML_P_5F_TLI)

FA_BICSummary <- c(FA_PA_V_3F_BIC,
                   FA_PA_V_4F_BIC,
                   FA_PA_V_5F_BIC,
                   FA_PA_P_3F_BIC,
                   FA_PA_P_4F_BIC,
                   FA_PA_P_5F_BIC,
                   FA_ML_V_3F_BIC,
                   FA_ML_V_4F_BIC,
                   FA_ML_V_5F_BIC,
                   FA_ML_P_3F_BIC,
                   FA_ML_P_4F_BIC,
                   FA_ML_P_5F_BIC)

FA_HighResidualRateSummary <- c(FA_PA_V_3F_HighResidualRate,
                                FA_PA_V_4F_HighResidualRate,
                                FA_PA_V_5F_HighResidualRate,
                                FA_PA_P_3F_HighResidualRate,
                                FA_PA_P_4F_HighResidualRate,
                                FA_PA_P_5F_HighResidualRate,
                                FA_ML_V_3F_HighResidualRate,
                                FA_ML_V_4F_HighResidualRate,
                                FA_ML_V_5F_HighResidualRate,
                                FA_ML_P_3F_HighResidualRate,
                                FA_ML_P_4F_HighResidualRate,
                                FA_ML_P_5F_HighResidualRate)

FA_AlgorithmSummary <- c("FA_PA_V_3F",
                         "FA_PA_V_4F",
                         "FA_PA_V_5F",
                         "FA_PA_P_3F",
                         "FA_PA_P_4F",
                         "FA_PA_P_5F",
                         "FA_ML_V_3F",
                         "FA_ML_V_4F",
                         "FA_ML_V_5F",
                         "FA_ML_P_3F",
                         "FA_ML_P_4F",
                         "FA_ML_P_5F")

FA_Summary <- cbind(FA_RMSSummary,
                    FA_TLISummary,
                    FA_BICSummary,
                    FA_HighResidualRateSummary,
                    FA_AlgorithmSummary)

FA_Summary <- as.data.frame(FA_Summary)
names(FA_Summary) <- c("RMS",
                       "TLI",
                       "BIC",
                       "HighResidualRate",
                       "Algorithm")

FA_Summary$RMS <- as.numeric(as.character(FA_Summary$RMS))
FA_Summary$TLI <- as.numeric(as.character(FA_Summary$TLI))
FA_Summary$BIC <- as.numeric(as.character(FA_Summary$BIC))
FA_Summary$HighResidualRate <- as.numeric(as.character(FA_Summary$HighResidualRate))

FA_Summary$Algorithm <- factor(FA_Summary$Algorithm ,
                                        levels = c("FA_PA_V_3F",
                                                   "FA_PA_V_4F",
                                                   "FA_PA_V_5F",
                                                   "FA_PA_P_3F",
                                                   "FA_PA_P_4F",
                                                   "FA_PA_P_5F",
                                                   "FA_ML_V_3F",
                                                   "FA_ML_V_4F",
                                                   "FA_ML_V_5F",
                                                   "FA_ML_P_3F",
                                                   "FA_ML_P_4F",
                                                   "FA_ML_P_5F"))

print(FA_Summary, row.names=FALSE)

(RMS_Plot <- dotplot(Algorithm ~ RMS,
                     data = FA_Summary,
                     main = "Algorithm Standardized Root Mean Square of the Residual Comparison",
                     ylab = "Algorithm",
                     xlab = "RMSR",
                     auto.key = list(adj = 1),
                     type=c("p", "h"),  
                     origin = 0,
                     alpha = 0.45,
                     pch = 16,
                     cex = 2))

(TLI_Plot <- dotplot(Algorithm ~ TLI,
                     data = FA_Summary,
                     main = "Algorithm Tucker-Lewis Fit Index Comparison",
                     ylab = "Algorithm",
                     xlab = "TLI",
                     auto.key = list(adj = 1),
                     type=c("p", "h"),  
                     origin = 0,
                     alpha = 0.45,
                     pch = 16,
                     cex = 2))

(BIC_Plot <- dotplot(Algorithm ~ BIC,
                     data = FA_Summary,
                     main = "Algorithm Bayesian Information Criterion Comparison",
                     ylab = "Algorithm",
                     xlab = "BIC",
                     auto.key = list(adj = 1),
                     type=c("p", "h"),  
                     origin = 0,
                     alpha = 0.45,
                     pch = 16,
                     cex = 2))

(HighResidualRate_Plot <- dotplot(Algorithm ~ HighResidualRate,
                     data = FA_Summary,
                     main = "Algorithm High Residual Rate Comparison",
                     ylab = "Algorithm",
                     xlab = "High Residual Rate",
                     auto.key = list(adj = 1),
                     type=c("p", "h"),  
                     origin = 0,
                     alpha = 0.45,
                     pch = 16,
                     cex = 2))

```

</details>

|
# **2. References**
|
| **[Book]** [Multiple Factor Analysis by Example Using R](https://www.oreilly.com/library/view/multiple-factor-analysis/9781498786690/) by Jerome Pages
| **[Book]** [Nonlinear Principal Component Analysis and Its Applications](https://link.springer.com/book/10.1007/978-981-10-0159-8#toc) by Yuichi Mori, Masahiro Kuroda and Naomichi Makino
| **[Book]** [Applied Predictive Modeling](http://appliedpredictivemodeling.com/) by Max Kuhn and Kjell Johnson
| **[Book]** [An Introduction to Statistical Learning](https://www.statlearning.com/) by Gareth James, Daniela Witten, Trevor Hastie and Rob Tibshirani
| **[Book]** [Multivariate Data Visualization with R](http://lmdvr.r-forge.r-project.org/figures/figures.html) by Deepayan Sarkar
| **[Book]** [Machine Learning](https://bookdown.org/ssjackson300/Machine-Learning-Lecture-Notes/) by Samuel Jackson
| **[Book]** [Data Modeling Methods](https://bookdown.org/larget_jacob/data-modeling-methods/) by Jacob Larget
| **[Book]** [Introduction to R and Statistics](https://saestatsteaching.tech/) by University of Western Australia
| **[Book]** [Feature Engineering and Selection: A Practical Approach for Predictive Models](http://www.feat.engineering/index.html) by Max Kuhn and Kjell Johnson
| **[Book]** [Introduction to Research Methods](https://bookdown.org/ejvanholm/Textbook/) by Eric van Holm
| **[Book]** [A Step-by-Step Guide to Exploratory Factor Analysis with R and RStudio](https://www.taylorfrancis.com/books/mono/10.4324/9781003120001/step-step-guide-exploratory-factor-analysis-rstudio-marley-watkins) by Marley Watkins
| **[R Package]** [AppliedPredictiveModeling](https://cran.r-project.org/web//packages/AppliedPredictiveModeling/AppliedPredictiveModeling.pdf) by Max Kuhn
| **[R Package]** [caret](https://topepo.github.io/caret/index.html) by Max Kuhn
| **[R Package]** [rpart](https://mran.microsoft.com/web/packages/rpart/rpart.pdf) by Terry Therneau and Beth Atkinson
| **[R Package]** [lattice](https://cran.r-project.org/web/packages/lattice/lattice.pdf) by  Deepayan Sarkar
| **[R Package]** [dplyr](https://cran.r-project.org/web/packages/dplyr/index.html/) by Hadley Wickham
| **[R Package]** [moments](https://cran.r-project.org/web/packages/moments/index.html) by Lukasz Komsta and Frederick
| **[R Package]** [skimr](https://cran.r-project.org/web/packages/skimr/skimr.pdf) by  Elin Waring
| **[R Package]** [RANN](https://cran.r-project.org/web/packages/RANN/RANN.pdf) by  Sunil Arya, David Mount, Samuel Kemp and Gregory Jefferis
| **[R Package]** [corrplot](https://cran.r-project.org/web/packages/corrplot/corrplot.pdf) by Taiyun Wei
| **[R Package]** [tidyverse](https://cran.r-project.org/web/packages/tidyverse/tidyverse.pdf) by Hadley Wickham
| **[R Package]** [lares](https://cran.rstudio.com/web/packages/lares/lares.pdf) by Bernardo Lares
| **[R Package]** [DMwR](https://mran.microsoft.com/snapshot/2016-05-02/web/packages/DMwR/DMwR.pdf) by Luis Torgo
| **[R Package]** [gridExtra](https://cran.r-project.org/web/packages/gridExtra/gridExtra.pdf) by Baptiste Auguie and Anton Antonov
| **[R Package]** [rattle](https://cran.r-project.org/web/packages/rattle/rattle.pdf) by Graham Williams
| **[R Package]** [RColorBrewer](https://cran.r-project.org/web//packages/RColorBrewer/RColorBrewer.pdf) by Erich Neuwirth
| **[R Package]** [stats](https://search.r-project.org/R/refmans/stats/html/00Index.html) by R Core Team
| **[R Package]** [factoextra](https://cran.r-project.org/web/packages/factoextra/factoextra.pdf) by Alboukadel Kassambara and Fabian Mundt
| **[R Package]** [FactoMineR](https://search.r-project.org/R/refmans/stats/html/00Index.html) by Francois Husson, Julie Josse, Sebastien Le and Jeremy Mazet
| **[R Package]** [gplots](https://cran.r-project.org/web/packages/gplots/gplots.pdf) by Tal Galili
| **[R Package]** [qgraph](https://cran.r-project.org/web/packages/qgraph/qgraph.pdf) by Sacha Epskamp
| **[R Package]** [ggplot2](https://search.r-project.org/R/refmans/stats/html/00Index.html) by Hadley Wickham, Winston Chang, Lionel Henry and Thomas Lin Pedersen
| **[R Package]** [psych](https://cran.r-project.org/web/packages/psych/psych.pdf) by William Revelle
| **[R Package]** [nFactors](https://cran.r-project.org/web/packages/nFactors/nFactors.pdf) by Gilles Raiche and David Magis
| **[R Package]** [MBESS](https://cran.r-project.org/web/packages/MBESS/MBESS.pdf) by Ken Kelley
| **[R Package]** [DandEFA](https://cran.r-project.org/web/packages/DandEFA/DandEFA.pdf) by Artur Manukyan, Ahmet Sedef, Erhan Cene and Ibrahim Demir
| **[R Package]** [EFAtools](https://cran.r-project.org/web/packages/EFAtools/EFAtools.pdf) by Markus Steiner and Silvia Grieder
| **[R Package]** [parameters](https://cran.r-project.org/web/packages/parameters/parameters.pdf) by Daniel Ludecke
| **[R Package]** [performance](https://cran.r-project.org/web/packages/performance/performance.pdf) by Daniel Ludecke
| **[Article]** [6 Dimensionality Reduction Techniques in R (with Examples)](https://cmdlinetips.com/2022/07/dimensionality-reduction-techniques-in-r/) by CMDLineTips Team
| **[Article]** [6 Dimensionality Reduction Algorithms With Python](https://machinelearningmastery.com/dimensionality-reduction-algorithms-with-python/) by Jason Brownlee
| **[Article]** [Introduction to Dimensionality Reduction for Machine Learning](https://machinelearningmastery.com/dimensionality-reduction-for-machine-learning/) by Jason Brownlee
| **[Article]** [Introduction to Dimensionality Reduction](https://www.geeksforgeeks.org/dimensionality-reduction/) by Geeks For Geeks
| **[Article]** [Factor Analysis with the psych package](https://m-clark.github.io/posts/2020-04-10-psych-explained/) by Michael Clark
| **[Article]** [Factor Analysis in R with Psych Package: Measuring Consumer Involvement](https://www.r-bloggers.com/2019/01/factor-analysis-in-r-with-psych-package-measuring-consumer-involvement/) by Peter Prevos
| **[Article]** [Factor Analysis in R](http://jinjian-mu.com/tutorial/2021-04-14-Factor%20Analysis/) by Jinjian Mu
| **[Article]** [How To: Use the psych package for Factor Analysis and Data Reduction](http://personality-project.org/r/psych/HowTo/factor.pdf) by William Revelle
| **[Article]** [A Practical Introduction to Factor Analysis: Exploratory Factor Analysis](https://stats.oarc.ucla.edu/spss/seminars/introduction-to-factor-analysis/a-practical-introduction-to-factor-analysis/) by UCLA Advanced Research Computing Team
| **[Article]** [Examining the Big 5 Personality Dataset with Factor Analysis](https://taridwong.github.io/posts/2022-01-01-efacfa/) by Tarid Wongvorachan
| **[Article]** [Principal Component Analysis versus Exploratory Factor Analysis](https://support.sas.com/resources/papers/proceedings/proceedings/sugi30/203-30.pdf) by Diana Suhr
| **[Article]** [Exploratory Factor Analysis](https://www.publichealth.columbia.edu/research/population-health-methods/exploratory-factor-analysis) by Columbia University Irving Medical Center
| **[Article]** [Factor Analysis Example](https://real-statistics.com/multivariate-statistics/factor-analysis/factor-analysis-example/) by Charles Zaiontz
| **[Article]** [Factor Analysis Guide with an Example](https://statisticsbyjim.com/basics/factor-analysis/) by Jim Frost
| **[Article]** [What Is Factor Analysis and How Does It Simplify Research Findings?](https://www.qualtrics.com/experience-management/research/factor-analysis/) by Qualtrics Team
| **[Article]** [How Can I Perform A Factor Analysis With Categorical (Or Categorical And Continuous) Variables?](https://stats.oarc.ucla.edu/stata/faq/how-can-i-perform-a-factor-analysis-with-categorical-or-categorical-and-continuous-variables/) by UCLA Advanced Research Computing Team
| **[Article]** [Factor Analysis on Ordinal Data Example in R (psych, homals)](https://alice86.github.io/2018/04/08/Factor-Analysis-on-Ordinal-Data-example-in-R-(psych,-homals)/) by Jiayu Wu
| **[Publication]** [Dandelion Plot: A Method for the Visualization of R-mode Exploratory Factor Analyses](https://link.springer.com/article/10.1007/s00180-014-0518-x) by Artur Manukyan, Erhan Cene, Ahmet Sedef and Ibrahim Demir (Computational Statistics) 
| **[Course]** [Applied Data Mining and Statistical Learning](https://online.stat.psu.edu/stat508/) by Penn State Eberly College of Science
|
|
|
|